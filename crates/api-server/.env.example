# Server Configuration
SERVER_HOST=0.0.0.0
SERVER_PORT=8080
SERVER_WORKERS=4

# Database Configuration
DATABASE_URL=sqlite:/var/lib/securellm/models.db

# Redis Configuration
REDIS_URL=redis://localhost:6379

# Provider Configuration

# DeepSeek
DEEPSEEK_ENABLED=true
DEEPSEEK_API_KEY=your-deepseek-api-key-here
DEEPSEEK_BASE_URL=https://api.deepseek.com

# OpenAI
OPENAI_ENABLED=false
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_BASE_URL=https://api.openai.com/v1

# Anthropic
ANTHROPIC_ENABLED=false
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Groq
GROQ_ENABLED=false
GROQ_API_KEY=your-groq-api-key-here
GROQ_BASE_URL=https://api.groq.com/openai/v1

# Cohere
COHERE_ENABLED=false
COHERE_API_KEY=your-cohere-api-key-here

# LlamaCpp/KoboldCPP (Local)
LLAMACPP_ENABLED=true
LLAMACPP_BASE_URL=http://localhost:5001

# Security
API_KEYS=
REQUIRE_AUTH=false

# Telemetry
LOG_LEVEL=info
OTLP_ENDPOINT=

# Optional: Load config from file instead
# CONFIG_PATH=/etc/securellm/config.toml