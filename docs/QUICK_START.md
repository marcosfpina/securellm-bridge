# üöÄ QUICK START - Guia R√°pido de Uso

## üìù TL;DR - Execute Isso Agora

```bash
# 1. Teste inicial (1 query, seguro)
python test_credits.py

# 2. Se funcionou, queime cr√©ditos!
NUM_QUERIES=100 python burn_credits_loadtest.py
```

---

## üéØ Cen√°rios de Uso

### Cen√°rio 1: "Quero validar que os cr√©ditos funcionam"

```bash
# Execute UMA query
python test_credits.py

# ‚úÖ Sucesso = c√≥digo 200
# ‚è∞ Aguarde 48h
# üîç Valide no BigQuery (veja se√ß√£o "Valida√ß√£o" abaixo)
```

---

### Cen√°rio 2: "Quero queimar R$ 100 de cr√©ditos rapidamente"

```bash
# R$ 100 ‚âà $18 USD ‚âà 4,500 queries
NUM_QUERIES=4500 MAX_WORKERS=10 python burn_credits_loadtest.py

# Tempo estimado: 1-2 horas
```

---

### Cen√°rio 3: "Quero esgotar TODOS os cr√©ditos GenAI"

```bash
# R$ 6.432,54 ‚âà 1,600 queries
NUM_QUERIES=1600 MAX_WORKERS=15 python burn_credits_loadtest.py

# ATEN√á√ÉO: Execute em m√∫ltiplas sess√µes se houver rate limits!
```

---

### Cen√°rio 4: "Tenho um Dialogflow CX Agent pronto"

```bash
# Configure
export DIALOGFLOW_AGENT_ID='seu-agent-id-aqui'
export DIALOGFLOW_LOCATION='us-central1'

# Execute
NUM_CONVERSATIONS=100 python burn_dialogflow_cx.py
```

---

## üîç Valida√ß√£o Financeira (IMPORTANTE!)

### Setup BigQuery Export (UMA VEZ)

1. Acesse: https://console.cloud.google.com/billing/export
2. Clique "Edit Settings" em "Detailed usage cost"
3. Escolha "Export to BigQuery"
4. Dataset: `billing_export` (crie se n√£o existir)
5. Salve

### Executar Auditoria

```bash
# Configure (pegue o nome da tabela no BigQuery)
export BILLING_EXPORT_DATASET='billing_export'
export BILLING_EXPORT_TABLE='gcp_billing_export_v1_XXXXXX_XXXXXX_XXXXXX'

# Execute
python audit_credits_bigquery.py
```

### Interpretar Resultados

```
‚úÖ net_cost_to_wallet = $0.00
   ‚Üí Cr√©dito aplicado corretamente!
   ‚Üí Continue usando com seguran√ßa

‚ö†Ô∏è  net_cost_to_wallet > $0.00
   ‚Üí VOC√ä EST√Å SENDO COBRADO!
   ‚Üí PARE e revise a arquitetura
```

---

## üõ†Ô∏è Troubleshooting R√°pido

### Erro: "DATA_STORE_ID n√£o configurado"

```bash
# Lista data stores dispon√≠veis
python manage_datastores.py

# Ou cria um novo
python manage_datastores.py  # e escolha 'y' quando perguntado

# Configure
export DATA_STORE_ID='ds-app-v4-5e020c93'
```

---

### Erro: "DIALOGFLOW_AGENT_ID n√£o configurado"

```bash
# 1. Crie um agent em:
#    https://dialogflow.cloud.google.com/cx/

# 2. Copie o Agent ID (formato UUID)

# 3. Configure
export DIALOGFLOW_AGENT_ID='xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx'
export DIALOGFLOW_LOCATION='us-central1'
```

---

### Erro: "Method not found" (GroundedGenerationServiceClient)

**Solu√ß√£o:** N√ÉO use `grounded_generation.py`! Use `test_credits.py` ou `burn_credits_loadtest.py`.

Motivo: `GroundedGenerationServiceClient` n√£o est√° implementado no servidor Google.

---

### Query retorna vazio / sem resposta AI

**Causa:** Data Store vazio (sem documentos)

**Impacto:** Ainda consome cr√©dito! Resposta AI pode ser gen√©rica.

**Solu√ß√£o (opcional):**
```bash
# Popular com documentos
mkdir -p knowledge_base
# Coloque PDFs/TXTs em knowledge_base/
python import_documents.py knowledge_base/
```

---

## üìä Monitoramento em Tempo Real

### Durante execu√ß√£o do load test:

```
[100/1000] ‚úÖ 98 | ‚ùå 2 | QPS: 5.23 | Custo: $0.3920
            ‚Üë      ‚Üë       ‚Üë           ‚Üë
         Sucesso Falhas  Queries/s   $ acumulado
```

**Sinais de Alerta:**
- Muitas falhas (‚ùå > 10%): Reduce MAX_WORKERS
- QPS muito baixo (< 1): Increase MAX_WORKERS
- Erros de quota: Pause e retry depois

---

## üí° Dicas de Otimiza√ß√£o

### 1. Paraleliza√ß√£o Ideal

```bash
# Conservador (seguro)
MAX_WORKERS=5

# Moderado (recomendado)
MAX_WORKERS=10

# Agressivo (teste antes!)
MAX_WORKERS=20
```

### 2. Executar em Background

```bash
# Com nohup
nohup python burn_credits_loadtest.py > burn.log 2>&1 &

# Monitor progresso
tail -f burn.log
```

### 3. Dividir em Lotes

```bash
# Ao inv√©s de 1,600 de uma vez:
for i in {1..4}; do
    NUM_QUERIES=400 python burn_credits_loadtest.py
    sleep 300  # 5 min entre lotes
done
```

---

## üìà Estimativas de Tempo e Custo

| Queries | Custo (USD) | Custo (BRL) | Tempo (10 workers) |
|---------|-------------|-------------|--------------------|
| 10      | $0.04       | R$ 0.22     | ~2 segundos        |
| 100     | $0.40       | R$ 2.20     | ~20 segundos       |
| 500     | $2.00       | R$ 11.00    | ~2 minutos         |
| 1,000   | $4.00       | R$ 22.00    | ~4 minutos         |
| 1,600   | $6.40       | R$ 35.20    | ~6 minutos         |

*Baseado em QPS m√©dio de ~3 queries/segundo com 10 workers*

---

## üéØ Workflow Recomendado

```bash
# DIA 1: Valida√ß√£o
python test_credits.py
# ‚úÖ Funcionou? √ìtimo!

# DIA 3: Auditoria
python audit_credits_bigquery.py
# ‚úÖ net_cost = $0? Perfeito!

# DIA 3+: Escalando
NUM_QUERIES=500 python burn_credits_loadtest.py
# Monitore, ajuste, repita

# SEMANAL: Monitor
python audit_credits_bigquery.py
# Acompanhe consumo real vs estimado
```

---

## üìû Refer√™ncias R√°pidas

**Console Principal:**
- Billing: https://console.cloud.google.com/billing/
- Agent Builder: https://console.cloud.google.com/gen-app-builder
- Dialogflow CX: https://dialogflow.cloud.google.com/cx/

**Comandos √öteis:**
```bash
# Ver APIs habilitadas
gcloud services list --enabled | grep -E 'discovery|dialogflow'

# Ver projeto atual
gcloud config get-value project

# Trocar projeto
gcloud config set project SEU_PROJECT_ID
```

---

## ‚ö° One-Liner para Queimar Tudo

```bash
# YOLO - Queima TODOS os cr√©ditos GenAI de uma vez
# (N√£o recomendado sem valida√ß√£o pr√©via!)
NUM_QUERIES=1600 MAX_WORKERS=15 AUTO_CONFIRM=true \
  python burn_credits_loadtest.py
```

**‚ö†Ô∏è USE COM CAUTELA! Valide com BigQuery primeiro!**
