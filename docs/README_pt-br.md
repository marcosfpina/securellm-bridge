# SecureLLM Bridge

Sistema seguro e isolado para comunicaÃ§Ã£o com LLMs (Cloud, Local, Provider, Serverless)

## ğŸ”’ SeguranÃ§a por Design

- Isolamento mÃ¡ximo de ambiente
- AutenticaÃ§Ã£o mÃºtua TLS
- Rate limiting adaptativo
- Auditoria completa
- Sandboxing de execuÃ§Ã£o
- Zero-trust architecture

## ğŸ“ Estrutura do Projeto

```
secure-llm-bridge/
â”œâ”€â”€ src/                    # CÃ³digo fonte principal
â”‚   â”œâ”€â”€ core/              # AbstraÃ§Ãµes principais (request, response, error)
â”‚   â”œâ”€â”€ security/          # MÃ³dulos de seguranÃ§a (TLS, crypto, secrets)
â”‚   â”œâ”€â”€ providers/         # ImplementaÃ§Ãµes de providers (DeepSeek, OpenAI, etc)
â”‚   â””â”€â”€ config.rs          # GestÃ£o de configuraÃ§Ã£o
â”‚
â”œâ”€â”€ cli/                    # AplicaÃ§Ã£o CLI
â”‚   â””â”€â”€ src/main.rs
â”‚
â”œâ”€â”€ docs/                   # DocumentaÃ§Ã£o completa
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ GETTING_STARTED.md
â”‚   â”œâ”€â”€ SECURITY.md
â”‚   â”œâ”€â”€ CONTRIBUTING.md
â”‚   â”œâ”€â”€ PROJETO_COMPLETO.md
â”‚   â””â”€â”€ QUICK_START.md
â”‚
â”œâ”€â”€ examples/               # Exemplos de uso
â”‚   â”œâ”€â”€ rust_api_example.rs
â”‚   â”œâ”€â”€ basic_usage.sh
â”‚   â””â”€â”€ config.toml.example
â”‚
â”œâ”€â”€ docker/                 # ConfiguraÃ§Ãµes Docker
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ Dockerfile.alpine
â”‚   â””â”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ nix/                    # ConfiguraÃ§Ãµes Nix/NixOS
â”‚   â”œâ”€â”€ flake.nix
â”‚   â””â”€â”€ flake.lock
â”‚
â”œâ”€â”€ config/                 # Arquivos de configuraÃ§Ã£o
â”‚   â””â”€â”€ config.toml
â”‚
â””â”€â”€ mnt/                    # Dados persistentes/montagens
```

## ğŸš€ Quick Start

```bash
# Build
cargo build --release

# Run CLI
cargo run --bin securellm -- chat --provider deepseek "Hello!"

# With Docker
docker build -t securellm -f docker/Dockerfile .
docker run --rm securellm --help
```

## ğŸ“š DocumentaÃ§Ã£o

Para documentaÃ§Ã£o completa, veja:
- [Getting Started](docs/GETTING_STARTED.md) - Guia completo do projeto
- [Security](docs/SECURITY.md) - Best practices de seguranÃ§a
- [Contributing](docs/CONTRIBUTING.md) - Como contribuir
- [Quick Start](docs/QUICK_START.md) - InÃ­cio rÃ¡pido
- [Projeto Completo](docs/PROJETO_COMPLETO.md) - VisÃ£o geral completa

## ğŸ¯ Providers Suportados

- **Cloud**: OpenAI, Anthropic, DeepSeek, Cohere
- **Local**: Ollama, llama.cpp, LocalAI
- **Custom**: Servidores prÃ³prios
- **Serverless**: AWS Lambda, GCP Functions, Azure Functions

## ğŸ“ License

MIT OR Apache-2.0
