# ðŸ§  PHANTOM Framework - Arquitetura Unificada

**VersÃ£o:** 2.0
**Data:** 2026-01-02
**Objetivo:** MigraÃ§Ã£o de phoenix-cloud-run para arquitetura modular Phantom

---

## ðŸ“‹ VisÃ£o Geral

O **Phantom Framework** Ã© um framework unificado que combina:

1. **Knowledge Extraction & RAG** (ex-CEREBRO)
2. **GCP Credit Management** (ex-phoenix-cloud-run root)
3. **Multi-Cloud Integrations** (extensÃ­vel)

### PrincÃ­pios de Design

- **DRY**: CÃ³digo duplicado consolidado em mÃ³dulos core
- **Modularidade**: Componentes independentes e reutilizÃ¡veis
- **Extensibilidade**: FÃ¡cil adicionar novos mÃ³dulos/integraÃ§Ãµes
- **HermÃ©tico**: OperaÃ§Ãµes isoladas, testÃ¡veis
- **Nix-First**: Ambientes reproduzÃ­veis e declarativos

---

## ðŸ—ï¸ Nova Estrutura de DiretÃ³rios

```
phantom/                              # Root do framework (renomeado de cerebro/)
â”‚
â”œâ”€â”€ core/                            # NÃºcleo do framework
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ gcp/                        # Google Cloud Platform (UNIFICADO)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ auth.py                # AutenticaÃ§Ã£o e configuraÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ billing.py             # BigQuery billing audit
â”‚   â”‚   â”œâ”€â”€ datastores.py          # Vertex AI Data Store management
â”‚   â”‚   â”œâ”€â”€ search.py              # Vertex AI Search / Grounded Generation
â”‚   â”‚   â””â”€â”€ dialogflow.py          # Dialogflow CX sessions
â”‚   â”‚
â”‚   â”œâ”€â”€ extraction/                # Code Knowledge Extraction
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ analyze_code.py       # AST/tree-sitter analysis
â”‚   â”‚   â”œâ”€â”€ generate_embeddings.py # Vector embeddings
â”‚   â”‚   â””â”€â”€ ingest_data.py        # Import to vector DB
â”‚   â”‚
â”‚   â”œâ”€â”€ rag/                       # RAG Server
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ server.py             # FastAPI server (local LLM)
â”‚   â”‚   â”œâ”€â”€ retrieval.py          # Vector similarity search
â”‚   â”‚   â””â”€â”€ generation.py         # LLM generation with context
â”‚   â”‚
â”‚   â””â”€â”€ utils/                     # Utilities compartilhadas
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py             # Configuration management
â”‚       â”œâ”€â”€ logging.py            # Logging setup
â”‚       â””â”€â”€ state.py              # State persistence
â”‚
â”œâ”€â”€ modules/                       # MÃ³dulos de aplicaÃ§Ã£o
â”‚   â”‚
â”‚   â”œâ”€â”€ credit_burner/            # GCP Credit Burning Module
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ loadtest.py          # Parallel query load testing
â”‚   â”‚   â”œâ”€â”€ dialogflow_sessions.py # Dialogflow CX automation
â”‚   â”‚   â””â”€â”€ audit.py             # Financial validation via BigQuery
â”‚   â”‚
â”‚   â”œâ”€â”€ knowledge/                # Knowledge Base Module
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ import_docs.py       # Document import to datastores
â”‚   â”‚   â””â”€â”€ query.py             # Knowledge base queries
â”‚   â”‚
â”‚   â””â”€â”€ nixos/                    # NixOS Integration Module (futuro)
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ service.py           # Systemd service generator
â”‚
â”œâ”€â”€ config/                       # Configuration files
â”‚   â”œâ”€â”€ repos.yaml               # Repository definitions for extraction
â”‚   â”œâ”€â”€ settings.yaml            # Global settings
â”‚   â””â”€â”€ examples/                # Example configs
â”‚       â”œâ”€â”€ repos.example.yaml
â”‚       â””â”€â”€ settings.example.yaml
â”‚
â”œâ”€â”€ scripts/                      # Utility scripts (legacy/standalone)
â”‚   â”œâ”€â”€ setup/
â”‚   â”‚   â”œâ”€â”€ setup_bigquery_export.sh
â”‚   â”‚   â””â”€â”€ setup_bigquery_simple.sh
â”‚   â”œâ”€â”€ validation/
â”‚   â”‚   â”œâ”€â”€ check_billing_table.sh
â”‚   â”‚   â””â”€â”€ validate_setup.py
â”‚   â””â”€â”€ migration/
â”‚       â””â”€â”€ migrate_from_phoenix.sh
â”‚
â”œâ”€â”€ docs/                         # Documentation
â”‚   â”œâ”€â”€ README.md                # Main overview
â”‚   â”œâ”€â”€ ARCHITECTURE.md          # This file
â”‚   â”œâ”€â”€ GETTING_STARTED.md       # Quick start guide
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”œâ”€â”€ CREDIT_BURNER.md     # Credit burner module docs
â”‚   â”‚   â”œâ”€â”€ KNOWLEDGE.md         # Knowledge extraction docs
â”‚   â”‚   â””â”€â”€ RAG.md               # RAG server docs
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ API_REFERENCE.md     # API documentation
â”‚
â”œâ”€â”€ tests/                        # Test suite
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ test_gcp_auth.py
â”‚   â”‚   â”œâ”€â”€ test_datastores.py
â”‚   â”‚   â””â”€â”€ test_search.py
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â””â”€â”€ test_credit_burner.py
â”‚   â””â”€â”€ integration/
â”‚       â””â”€â”€ test_e2e.py
â”‚
â”œâ”€â”€ data/                         # Data directory (gitignored)
â”‚   â”œâ”€â”€ knowledge_base/
â”‚   â”œâ”€â”€ vector_db/
â”‚   â””â”€â”€ cache/
â”‚
â”œâ”€â”€ .archive/                     # Deprecated files (for reference)
â”‚   â”œâ”€â”€ main.py                  # Old grounded generation attempt
â”‚   â”œâ”€â”€ grounded_generation.py
â”‚   â””â”€â”€ test_grounded_v1.py
â”‚
â”œâ”€â”€ phantom.py                    # Main CLI entry point
â”œâ”€â”€ flake.nix                     # Nix development environment
â”œâ”€â”€ flake.lock
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ pyproject.toml               # Python project metadata
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md                     # Project overview
```

---

## ðŸ”„ Mapeamento de MigraÃ§Ã£o

### Arquivos Duplicados â†’ Consolidados

| Arquivo Original | LocalizaÃ§Ã£o Nova | MÃ³dulo Core |
|-----------------|------------------|-------------|
| `manage_datastores.py` (root) | `core/gcp/datastores.py` | `phantom.core.gcp` |
| `manage_datastores.py` (cerebro) | *(removido)* | - |
| `test_credits.py` (root) | `modules/credit_burner/validate.py` | `phantom.modules.credit_burner` |
| `test_credits.py` (cerebro) | *(removido)* | - |
| `validate_credits.py` (root) | `core/gcp/auth.py` | `phantom.core.gcp` |
| `validate_credits.py` (cerebro) | *(removido)* | - |
| `cerebro/src/server.py` | `core/rag/server.py` | `phantom.core.rag` |
| `cerebro/bin/02_analyze_code.py` | `core/extraction/analyze_code.py` | `phantom.core.extraction` |
| `cerebro/bin/03_ingest_data.py` | `core/extraction/ingest_data.py` | `phantom.core.extraction` |
| `cerebro/bin/03_generate_embeddings.py` | `core/extraction/generate_embeddings.py` | `phantom.core.extraction` |

### Scripts de AplicaÃ§Ã£o â†’ MÃ³dulos

| Script Original | MÃ³dulo Novo | Responsabilidade |
|----------------|-------------|------------------|
| `burn_credits_loadtest.py` | `modules/credit_burner/loadtest.py` | Parallel load testing |
| `burn_dialogflow_cx.py` | `modules/credit_burner/dialogflow_sessions.py` | Dialogflow automation |
| `audit_credits_bigquery.py` | `modules/credit_burner/audit.py` | BigQuery financial audit |
| `import_documents.py` | `modules/knowledge/import_docs.py` | Document import |
| `cerebro/real.py` | `modules/knowledge/query.py` | Grounded search queries |

### Arquivos Deprecados â†’ Archive

| Arquivo | Motivo | Destino |
|---------|--------|---------|
| `main.py` | HTTP 501 error - API nÃ£o funciona | `.archive/main.py` |
| `grounded_generation.py` | Mesmo problema | `.archive/grounded_generation.py` |
| `test_grounded_v1.py` | DiagnÃ³stico - nÃ£o mais necessÃ¡rio | `.archive/test_grounded_v1.py` |

---

## ðŸ§© MÃ³dulos Core

### 1. `phantom.core.gcp`

**Responsabilidade:** AbstraÃ§Ã£o unificada para Google Cloud Platform APIs

**Componentes:**

```python
# core/gcp/auth.py
def get_credentials() -> Credentials
def get_project_id() -> str
def validate_setup() -> SetupStatus

# core/gcp/datastores.py
class DataStoreManager:
    def list() -> List[DataStore]
    def create(config: DataStoreConfig) -> DataStore
    def delete(data_store_id: str) -> None
    def get(data_store_id: str) -> DataStore

# core/gcp/search.py
class VertexAISearch:
    def search(query: str, **kwargs) -> SearchResponse
    def grounded_search(query: str, **kwargs) -> GroundedResponse

# core/gcp/billing.py
class BillingAuditor:
    def query_usage(start_date, end_date) -> UsageReport
    def validate_credits() -> CreditStatus
    def export_report(format: str) -> Path

# core/gcp/dialogflow.py
class DialogflowCXManager:
    def create_session() -> Session
    def detect_intent(session, query) -> Response
    def stream_conversation(session, queries) -> AsyncIterator[Response]
```

### 2. `phantom.core.extraction`

**Responsabilidade:** Code analysis e knowledge extraction

**Componentes:**

```python
# core/extraction/analyze_code.py
class CodeAnalyzer:
    def analyze_python(file_path: Path) -> List[Artifact]
    def analyze_nix(file_path: Path) -> List[Artifact]
    def analyze_repository(repo_path: Path) -> RepositoryKnowledge

# core/extraction/generate_embeddings.py
class EmbeddingGenerator:
    def generate(artifacts: List[Artifact]) -> List[Embedding]
    def store_to_chromadb(embeddings: List[Embedding]) -> None
    def store_to_vertex_ai(embeddings: List[Embedding]) -> None

# core/extraction/ingest_data.py
class DataIngester:
    def ingest_local_files(paths: List[Path]) -> None
    def ingest_from_git(repo_url: str) -> None
    def ingest_to_datastore(data_store_id: str, docs: List[Document]) -> None
```

### 3. `phantom.core.rag`

**Responsabilidade:** Retrieval-Augmented Generation server

**Componentes:**

```python
# core/rag/server.py
class PhantomRAGServer:
    def __init__(model_name: str, db_path: Path)
    def retrieve(query: str, top_k: int) -> List[Artifact]
    def generate(query: str, context: List[Artifact]) -> str

# FastAPI endpoints:
# - POST /query
# - GET /health
# - GET /stats

# core/rag/retrieval.py
class VectorRetriever:
    def similarity_search(query: str, top_k: int) -> List[Result]
    def hybrid_search(query: str, filters: Dict) -> List[Result]

# core/rag/generation.py
class LLMGenerator:
    def generate_with_context(query: str, context: str) -> str
    def stream_generate(query: str, context: str) -> AsyncIterator[str]
```

---

## ðŸŽ¯ MÃ³dulos de AplicaÃ§Ã£o

### 1. `phantom.modules.credit_burner`

**Objetivo:** Consumir crÃ©ditos GCP de forma auditÃ¡vel

**Interface CLI:**

```bash
# Validar setup
phantom credit-burner validate

# Load test com queries paralelas
phantom credit-burner loadtest --workers 10 --queries 1000

# Dialogflow CX sessions
phantom credit-burner dialogflow --sessions 100 --conversations 5

# Audit financeiro
phantom credit-burner audit --start-date 2025-12-01
```

### 2. `phantom.modules.knowledge`

**Objetivo:** Gerenciar knowledge base e document import

**Interface CLI:**

```bash
# Importar documentos
phantom knowledge import --source ./docs --datastore my-ds

# Query knowledge base
phantom knowledge query "Como configurar NixOS?"

# List datastores
phantom knowledge datastores list
```

---

## ðŸ”Œ CLI Principal: `phantom.py`

**Arquitetura:**

```python
#!/usr/bin/env python3
"""
PHANTOM Framework - Unified CLI
"""
import typer
from phantom.core import gcp, extraction, rag
from phantom.modules import credit_burner, knowledge

app = typer.Typer(name="phantom", help="PHANTOM Framework CLI")

# Subcommands
app.add_typer(credit_burner.cli.app, name="credit-burner")
app.add_typer(knowledge.cli.app, name="knowledge")
app.add_typer(gcp.cli.app, name="gcp")
app.add_typer(rag.cli.app, name="rag")

@app.command()
def init(project_type: str = "full"):
    """Initialize a new Phantom project"""
    # Setup directories, configs, etc.
    pass

@app.command()
def validate():
    """Validate entire Phantom setup"""
    # Check GCP auth, APIs, billing, etc.
    pass

if __name__ == "__main__":
    app()
```

**Uso:**

```bash
phantom --help
phantom validate
phantom gcp datastores list
phantom credit-burner loadtest --workers 5
phantom rag serve --model mistral-7b --port 8000
phantom knowledge query "What is RAG?"
```

---

## ðŸ”§ ConfiguraÃ§Ã£o Unificada

### `config/settings.yaml`

```yaml
project:
  name: phantom
  version: 2.0.0

gcp:
  project_id: gen-lang-client-0530325234
  location: global
  default_datastore: ds-app-v4-5e020c93

  billing:
    dataset: billing_export
    table: gcp_billing_export

  credits:
    genai_app_builder: 6432.54  # BRL
    dialogflow_cx: 3646.57      # BRL

rag:
  model: TheBloke/Mistral-7B-Instruct-v0.2-GPTQ
  quantization: 4bit
  db_path: ./data/vector_db/chromadb
  top_k: 5

extraction:
  repos_config: ./config/repos.yaml
  output_dir: ./data/extraction
  languages:
    - python
    - nix
    - rust
    - go

modules:
  credit_burner:
    enabled: true
    default_workers: 10

  knowledge:
    enabled: true
    auto_index: true
```

---

## ðŸ“¦ DependÃªncias Unificadas

### `requirements.txt` (consolidado)

```txt
# Google Cloud
google-cloud-discoveryengine>=0.11.0
google-cloud-storage>=2.10.0
google-cloud-aiplatform>=1.38.0
google-cloud-billing>=1.11.0
google-cloud-bigquery>=3.14.0
google-cloud-dialogflow-cx>=1.20.0
google-auth>=2.25.0

# RAG & Embeddings
fastapi>=0.109.0
uvicorn>=0.27.0
chromadb>=0.4.22
sentence-transformers>=2.3.0
transformers>=4.36.0
torch>=2.1.0
accelerate>=0.26.0
bitsandbytes>=0.41.0

# Code Analysis
tree-sitter>=0.20.4
tree-sitter-languages>=1.10.0
gitpython>=3.1.40
pygments>=2.17.0

# Document Processing
beautifulsoup4>=4.12.0
markdown>=3.5.0
pypdf>=3.17.0

# CLI & Utils
typer>=0.9.0
rich>=13.7.0
pydantic>=2.5.0
pyyaml>=6.0.1
python-dotenv>=1.0.0
tqdm>=4.66.0
```

---

## ðŸš€ Migration Workflow

### Fase 1: Setup Nova Estrutura âœ…

1. Renomear `cerebro/` â†’ `phantom/`
2. Criar diretÃ³rios: `core/`, `modules/`, `config/`, `docs/`
3. Mover `.archive/` para arquivos deprecados

### Fase 2: Consolidar Core Modules â³

1. Unificar `manage_datastores.py` â†’ `core/gcp/datastores.py`
2. Unificar `validate_credits.py` â†’ `core/gcp/auth.py`
3. Criar `core/gcp/search.py` (SearchServiceClient)
4. Criar `core/gcp/billing.py` (BigQuery audit)
5. Criar `core/gcp/dialogflow.py` (DialogflowCX)

### Fase 3: Migrar Application Modules â³

1. `burn_credits_loadtest.py` â†’ `modules/credit_burner/loadtest.py`
2. `burn_dialogflow_cx.py` â†’ `modules/credit_burner/dialogflow_sessions.py`
3. `audit_credits_bigquery.py` â†’ `modules/credit_burner/audit.py`
4. `import_documents.py` â†’ `modules/knowledge/import_docs.py`

### Fase 4: CLI Unificado â³

1. Criar `phantom.py` com Typer
2. Implementar subcommands para cada mÃ³dulo
3. Adicionar auto-complete (zsh/bash)

### Fase 5: DocumentaÃ§Ã£o â³

1. README.md principal
2. Docs por mÃ³dulo
3. API reference
4. Migration guide

### Fase 6: Testing & Validation â³

1. Unit tests para core modules
2. Integration tests
3. E2E test do credit burner workflow
4. Smoke tests

---

## ðŸŽ¨ Design Decisions

### Por que Phantom?

- **CEREBRO** era focado em knowledge extraction
- **PHANTOM** abrange todo o framework (knowledge + cloud + integrations)
- Nome curto, memorÃ¡vel, extensÃ­vel

### Por que nÃ£o apenas refatorar in-place?

- Evitar breaking changes durante migraÃ§Ã£o
- Permitir rollback fÃ¡cil
- Documentar processo de transformaÃ§Ã£o
- Criar oportunidade para limpar cÃ³digo legado

### Por que mÃ³dulos separados?

- **Separation of Concerns**: cada mÃ³dulo tem responsabilidade Ãºnica
- **Testabilidade**: mÃ³dulos testÃ¡veis independentemente
- **ReutilizaÃ§Ã£o**: core modules podem ser usados em outros projetos
- **Manutenibilidade**: mudanÃ§as isoladas nÃ£o quebram sistema todo

---

## ðŸ“Š MÃ©tricas de Sucesso

- âœ… Zero duplicaÃ§Ã£o de cÃ³digo (DRY)
- âœ… Todos os workflows originais funcionando
- âœ… CLI unificado e consistente
- âœ… DocumentaÃ§Ã£o completa e atualizada
- âœ… Tests com >80% coverage
- âœ… Nix flake validado (`nix flake check`)
- âœ… Performance mantida ou melhorada

---

## ðŸ”® Futuro / Roadmap

### v2.1 - Multi-Cloud Support
- AWS Bedrock integration
- Azure OpenAI integration
- Local-only mode (sem cloud)

### v2.2 - Enhanced RAG
- Multi-modal RAG (images, PDFs)
- Graph-based retrieval
- Fine-tuning support

### v2.3 - DevOps Integration
- CI/CD pipelines
- Kubernetes deployment
- Terraform modules

### v3.0 - Phantom Platform
- Web UI
- API Gateway
- Multi-user support
- Usage analytics

---

**Autor:** Phantom Team
**Status:** ðŸš§ Em Desenvolvimento
**Last Updated:** 2026-01-02
