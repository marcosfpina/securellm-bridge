#!/usr/bin/env python3
"""
03_ingest_data.py - O JEITO CERTO DE INGERIR (Burn Credits Mode)
Em vez de gerar embeddings na m√£o (caro), importamos para o Data Store.
O Vertex AI Search faz a indexa√ß√£o/vetoriza√ß√£o por conta da casa (cr√©ditos).
"""
import os
import json
from typing import List, Dict
from google.cloud import discoveryengine_v1beta as discoveryengine
from google.api_core.client_options import ClientOptions

def import_documents(project_id: str, location: str, data_store_id: str, input_jsonl: str):
    print(f"üöÄ Iniciando Ingest√£o Segura (Credit-Funded)...")

    # 1. Configura Client no Endpoint Discovery Engine (Cr√©ditos ‚úÖ)
    client_options = (
        ClientOptions(api_endpoint=f"{location}-discoveryengine.googleapis.com")
        if location != "global" else None
    )
    client = discoveryengine.DocumentServiceClient(client_options=client_options)

    # 2. Define o caminho do Data Store
    parent = client.branch_path(
        project=project_id,
        location=location,
        data_store=data_store_id,
        branch="default_branch"
    )

    # 3. Prepara o Request de Importa√ß√£o (GCS ou Inline)
    # Para 2600 arquivos, o ideal √© subir o JSONL para o GCS (Google Cloud Storage) primeiro
    # Mas aqui vamos assumir que voc√™ tem um JSONL local e vamos usar Inline (limite menor) ou GCS.
    # Recomenda√ß√£o: Use GCS para "Burn Credits" em massa.

    print("‚ö†Ô∏è  Para ingest√£o em massa, suba o arquivo 'all_artifacts.jsonl' para um Bucket GCS.")
    gcs_uri = f"gs://{project_id}-staging/all_artifacts.jsonl"

    request = discoveryengine.ImportDocumentsRequest(
        parent=parent,
        gcs_source=discoveryengine.GcsSource(input_uris=[gcs_uri]),
        # O modo INCREMENTAL garante que voc√™ possa rodar de novo sem quebrar tudo
        reconciliation_mode=discoveryengine.ImportDocumentsRequest.ReconciliationMode.INCREMENTAL,
    )

    # 4. Dispara a opera√ß√£o (Long Running)
    operation = client.import_documents(request=request)
    print(f"‚è≥ Importa√ß√£o iniciada: {operation.operation.name}")
    print("   O Vertex AI Search agora est√° gerando embeddings e indexando (coberto pelo cr√©dito).")

    # Opcional: operation.result() para esperar

if __name__ == "__main__":
    # Exemplo de uso
    import_documents(
        project_id=os.getenv("GCP_PROJECT"),
        location="global",
        data_store_id=os.getenv("DATA_STORE_ID"),
        input_jsonl="data/analyzed/all_artifacts.jsonl"
    )
